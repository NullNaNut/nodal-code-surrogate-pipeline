{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c40d9bc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-12 03:00:37.632879: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-12 03:00:37.988626: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-09-12 03:00:37.988646: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-09-12 03:00:37.990601: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-09-12 03:00:38.151244: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-12 03:00:39.063630: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Conv3D, Add, Activation, Flatten, Dense, add\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# MLflow 라이브러리 임포트\n",
    "import mlflow\n",
    "import mlflow.tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e30fb14b",
   "metadata": {},
   "source": [
    "원본 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "523745cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 서버 내 학습데이터 디렉토리 경로\n",
    "dataset_dir_path = Path(\"/home/jskwon/Desktop/project-nodal-surrogate/datasets/nodal-code-surrogate-data-registry/ASTRA/const_power_operation/first_cycle_depletion/iSMR/run_250814_cycle_length/processed_data\")\n",
    "artifacts_dir_path = Path(\"/home/jskwon/Desktop/project-nodal-surrogate/workspace/nodal-code-surrogate-pipeline/notebooks/temp-training-model-cycle_length/temp-artifacts\")\n",
    "\n",
    "# 특정 dir path + \"파일명\"\n",
    "mac_xs_voxel_4d_filename = \"mac_xs_voxel_4d_250814.npy\"\n",
    "cycle_length_csv_filename = \"efpd_interpolation_results.csv\"\n",
    "\n",
    "mac_xs_voxel_4d = np.load(dataset_dir_path/mac_xs_voxel_4d_filename)\n",
    "df_cycle_length = pd.read_csv(dataset_dir_path/cycle_length_csv_filename, index_col=0) \n",
    "cycle_length = df_cycle_length.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e7c4af",
   "metadata": {},
   "source": [
    "데이터 클린징\n",
    "- cycle_length 데이터 중, 해당 값을 못찾은 케이스 존재"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e06b4697",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['1058.409090909091'],\n",
       "       ['976.2857142857143'],\n",
       "       ['1036.3636363636363'],\n",
       "       ...,\n",
       "       ['Summary Not Found'],\n",
       "       ['1056.530612244898'],\n",
       "       ['843.1034482758621']], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cycle_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "041e436c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. cycle_length 데이터를 처리하며 invalid_indice 기록\n",
    "\n",
    "valid_data_list = []\n",
    "invalid_indices_list = []\n",
    "\n",
    "for idx, value in enumerate(cycle_length):\n",
    "    # cycle_length 데이터가, 1차원 배열이여야 하지만 마지막 차원이 하나 더 존재하므로 제거\n",
    "    item = value[0]\n",
    "    \n",
    "    # 문자열을 실수로 변환\n",
    "        # 변환 시도 성공: 실수형 데이터\n",
    "        # 변환 실패 : 문자열 문구가 기록된 리스트의 요소\n",
    "    try:\n",
    "        float_value = float(item)\n",
    "        valid_data_list.append(float_value) # 변환 성공시 valid_data_list에 추가\n",
    "    except ValueError:\n",
    "        invalid_indices_list.append(idx) # 변환 실패시, invalid_indice_list에 기록\n",
    "\n",
    "# 리스트들을 최종적인 NumPy 배열로 변환\n",
    "clean_cycle_length = np.array(valid_data_list)\n",
    "invalid_indices = np.array(invalid_indices_list)\n",
    "\n",
    "\n",
    "# 2. invalid_indices를 이용해 mac_xs_4d를 제거\n",
    "\n",
    "clean_mac_xs_voxel_4d = np.delete(mac_xs_voxel_4d,\n",
    "                                  invalid_indices,\n",
    "                                  axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3f615f8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data after cleansing - mac_xs_voxel: (9191, 24, 5, 5, 10)\n",
      "Shape of data after cleansing - cycle_length: (9191,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of data after cleansing - mac_xs_voxel:\" ,clean_mac_xs_voxel_4d.shape)\n",
    "print(\"Shape of data after cleansing - cycle_length:\", clean_cycle_length.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8e470629",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/12 04:40:23 INFO mlflow.tracking.fluent: Experiment with name 'mlflow_test_first_250912' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='file:///home/jskwon/Desktop/project-nodal-surrogate/datasets/nodal-code-surrogate-data-registry/ASTRA/const_power_operation/first_cycle_depletion/iSMR/run_250814_cycle_length/processed_data/mlruns/335135521009550182', creation_time=1757652023016, experiment_id='335135521009550182', last_update_time=1757652023016, lifecycle_stage='active', name='mlflow_test_first_250912', tags={}>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 실험 이름 설정 (MLflow UI에서 보일 그룹 이름)\n",
    "mlflow.set_experiment(\"mlflow_test_first_250912\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774e193c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLflow 로깅이 완료되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Conv3D, Add, Activation, Flatten, Dense, add\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# MLflow 라이브러리 임포트\n",
    "import mlflow\n",
    "import mlflow.tensorflow\n",
    "\n",
    "# ----------------------------------------\n",
    "# 1. 데이터 로딩 (기존 코드와 동일)\n",
    "# ----------------------------------------\n",
    "# 서버 내 학습데이터 디렉토리 경로\n",
    "dataset_dir_path = Path(\"/home/jskwon/Desktop/project-nodal-surrogate/datasets/nodal-code-surrogate-data-registry/ASTRA/const_power_operation/first_cycle_depletion/iSMR/run_250814_cycle_length/processed_data\")\n",
    "artifacts_dir_path = Path(\"/home/jskwon/Desktop/project-nodal-surrogate/workspace/nodal-code-surrogate-pipeline/notebooks/temp-training-model-cycle_length/temp-artifacts\")\n",
    "\n",
    "# 특정 dir path + \"파일명\"\n",
    "mac_xs_voxel_4d_filename = \"mac_xs_voxel_4d_250814.npy\"\n",
    "cycle_length_csv_filename = \"efpd_interpolation_results.csv\"\n",
    "\n",
    "mac_xs_voxel_4d = np.load(dataset_dir_path / mac_xs_voxel_4d_filename)\n",
    "df_cycle_length = pd.read_csv(dataset_dir_path / cycle_length_csv_filename, index_col=0)\n",
    "cycle_length = df_cycle_length.to_numpy()\n",
    "\n",
    "# (가정) 이 부분에 train/validation 데이터 분할 코드가 있다고 가정합니다.\n",
    "# 예: from sklearn.model_selection import train_test_split\n",
    "# x_train, x_valid, y_train, y_valid = train_test_split(mac_xs_voxel_4d, cycle_length, test_size=0.2)\n",
    "# 이 예시에서는 변수들이 이미 있다고 가정하고 진행합니다.\n",
    "\n",
    "# ----------------------------------------\n",
    "# 2. 모델 정의 (기존 코드와 동일)\n",
    "# ----------------------------------------\n",
    "def residual_block_3d(input_tensor, num_filters, kernel_size):\n",
    "    # First convolution\n",
    "    x = Conv3D(num_filters, kernel_size=kernel_size, strides=(1, 1, 1), padding='same')(input_tensor)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    # Second convolution\n",
    "    x = Conv3D(num_filters, kernel_size=(1, 1, 1), strides=(1, 1, 1), padding='same')(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    # Shortcut path\n",
    "    shortcut = Conv3D(num_filters, kernel_size=(1, 1, 1), strides=(1, 1, 1), padding='same')(input_tensor)\n",
    "\n",
    "    # Add shortcut to output of conv layers\n",
    "    x = add([x, shortcut])\n",
    "    x = Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "# ----------------------------------------\n",
    "# 3. MLflow 실험 시작 및 모델 훈련\n",
    "# ----------------------------------------\n",
    "# 실험 이름 설정 (MLflow UI에서 보일 그룹 이름)\n",
    "mlflow.set_experiment(\"cycle_length_prediction\")\n",
    "\n",
    "# MLflow 실행(Run) 시작\n",
    "with mlflow.start_run(run_name=\"ResNet_lr1e-4_epochs150\"):\n",
    "    # --- MLflow를 위한 추가 로깅 ---\n",
    "    # 데이터 소스 정보 로깅\n",
    "    mlflow.log_param(\"dataset_dir\", str(dataset_dir_path))\n",
    "    mlflow.log_param(\"input_data_file\", mac_xs_voxel_4d_filename)\n",
    "    mlflow.log_param(\"target_data_file\", cycle_length_csv_filename)\n",
    "    \n",
    "    # 하이퍼파라미터 정의 및 로깅\n",
    "    learning_rate = 1e-4\n",
    "    epochs = 150\n",
    "    input_shape = (24, 5, 5, 10)\n",
    "\n",
    "    mlflow.log_param(\"learning_rate\", learning_rate)\n",
    "    mlflow.log_param(\"epochs\", epochs)\n",
    "    mlflow.log_param(\"input_shape\", str(input_shape))\n",
    "    \n",
    "    # --- 모델 구성 및 컴파일 ---\n",
    "    input_lp = Input(shape=input_shape, name='input_lp')\n",
    "    x = residual_block_3d(input_lp, 99, (15, 5, 5))\n",
    "    x = residual_block_3d(x, 99, (15, 3, 3))\n",
    "    x = residual_block_3d(x, 99, (3, 3, 3))\n",
    "    x = residual_block_3d(x, 1, (3, 3, 3))\n",
    "    x_flatten = Flatten(name='flatten_features')(x)\n",
    "    x_dense = Dense(128, activation='relu', name='dense_layer_1')(x_flatten)\n",
    "    x_dense = Dense(64, activation='relu', name='dense_layer_2')(x_dense)\n",
    "    output_scalar = Dense(1, name='output_scalar')(x_dense)\n",
    "\n",
    "    model = Model(inputs=input_lp, outputs=output_scalar)\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='mse')\n",
    "    \n",
    "    # 모델 아키텍처를 텍스트 파일로 저장하여 아티팩트로 로깅\n",
    "    summary_list = []\n",
    "    model.summary(print_fn=lambda x: summary_list.append(x))\n",
    "    model_summary = \"\\n\".join(summary_list)\n",
    "    mlflow.log_text(model_summary, \"model_summary.txt\")\n",
    "\n",
    "    # TensorFlow Autologging 활성화\n",
    "    mlflow.tensorflow.autolog()\n",
    "\n",
    "    # --- 데이터 타입 변환 및 모델 학습 ---\n",
    "    # (가정) x_train, y_train, x_valid, y_valid 변수가 준비되어 있어야 합니다.\n",
    "    # x_train = np.array(x_train, dtype=np.float32)\n",
    "    # y_train = np.array(y_train, dtype=np.float32)\n",
    "    # x_valid = np.array(x_valid, dtype=np.float32)\n",
    "    # y_valid = np.array(y_valid, dtype=np.float32)\n",
    "\n",
    "    # history = model.fit(x_train, y_train, epochs=epochs, validation_data=(x_valid, y_valid))\n",
    "\n",
    "    # --- 기존 모델 저장 코드 (필요시 유지) ---\n",
    "    # Autolog가 모델을 저장해주므로 이 코드는 사실상 불필요하지만, 백업용으로 둘 수 있습니다.\n",
    "    # model.save(\"experiment-250911-cycle_length-v0.h5\")\n",
    "\n",
    "print(\"MLflow 로깅이 완료되었습니다.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2_14",
   "language": "python",
   "name": "tf2_14"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
